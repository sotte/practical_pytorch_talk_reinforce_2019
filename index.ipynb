{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](notebooks/img/the_real_reason.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <img src=\"notebooks/img/pytorch-logo.png\" width=\"80\"> Practical PyTorch 101\n",
    "Stefan Otte | stefan.otte@gmail.com | https://nodata.science\n",
    "\n",
    "Thanks reinforce!\n",
    "\n",
    "(Accompanying Workshop on the 22nd at 13:30)\n",
    "\n",
    "(Material https://github.com/sotte/pytorch_tutorial WIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Goals\n",
    "- Understand major PyTorch concepts\n",
    "\n",
    "## Prerequisites\n",
    "- understand deep learning basics\n",
    "- (have used a deep learning framework)\n",
    "\n",
    "## Workshop\n",
    "- Accompanying Workshop tomorrow at 13:30\n",
    "- Material https://github.com/sotte/pytorch_tutorial *WIP*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Tyrrany of Choice & Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is *PyTorch*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> \"PyTorch - Tensors and Dynamic neural networks in Python with strong GPU acceleration. PyTorch is a deep learning framework for fast, flexible experimentation.\" -- pytorch.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **eager execution** or **build-by-run** (not build-then-run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- PyTorch is like numpy (on the GPU and with autograd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- concise API surface and *good abstractions*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- PyTorch is just stupid Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](notebooks/img/dynamic_graph.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if branch. x: tensor(-2., requires_grad=True)\n",
      "val:  -0.0\n",
      "grad: 0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "def my_relu(x: torch.FloatTensor) -> torch.FloatTensor:\n",
    "    # set_trace()  # <-- this!\n",
    "    if x < 0:\n",
    "        print(\"if branch. x:\", x)\n",
    "        return x * 0\n",
    "    return x\n",
    "\n",
    "x = torch.tensor(-2., requires_grad=True)\n",
    "res = my_relu(x)\n",
    "res.backward()\n",
    "\n",
    "print(\"val: \", res.item())\n",
    "print(\"grad:\", x.grad.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*\"I don't get it\"* vs *\"WOOOW!\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What you don't see:\n",
    "`session.run(), tf.control_dependencies(), tf.while_loop(), tf.cond(), tf.global_variables_initializer()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TensorFlow 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PyTorch Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models\n",
    "\n",
    "from ipdb import set_trace\n",
    "\n",
    "DEVICE = torch.device(\n",
    "    \"cuda:0\" if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Tensors and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(3, 3)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a + a @ a.t();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a = a.to(DEVICE)\n",
    "a + a @ a.t();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.cpu();  # a.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `torch.nn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(20, 64, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = torch.rand(16, 1, 24, 24)\n",
    "model(batch);  # forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(20, 64, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        return F.adaptive_avg_pool2d(x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def bn_conv_relu(in_channels, out_channels, kernel_size=5):\n",
    "    return nn.Sequential(\n",
    "        nn.BatchNorm2d(in_channels),\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size),\n",
    "        nn.ReLU(),\n",
    "    )\n",
    "\n",
    "model = nn.Sequential(\n",
    "    OrderedDict({\n",
    "        \"conv1\": bn_conv_relu(1, 20, 7),\n",
    "        \"conv2\": bn_conv_relu(20, 64),\n",
    "        \"aap\": nn.AdaptiveAvgPool2d(1),\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv1): Sequential(\n",
       "    (0): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv2d(1, 20, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (aap): AdaptiveAvgPool2d(output_size=1)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# move the model to the GPU\n",
    "model = model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=1, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# nn.Linear as example of nn.Module\n",
    "lin = nn.Linear(1, 3, bias=True)\n",
    "print(lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight', tensor([[0.5689],\n",
       "                      [0.7325],\n",
       "                      [0.9801]])),\n",
       "             ('bias', tensor([ 0.1557, -0.9874,  0.5309]))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.5689],\n",
      "        [0.7325],\n",
      "        [0.9801]], requires_grad=True)\n",
      "\n",
      "Parameter containing:\n",
      "tensor([ 0.1557, -0.9874,  0.5309], requires_grad=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for p in lin.parameters():\n",
    "    print(p)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Linear(in_features=1, out_features=3, bias=True) with uniform\n"
     ]
    }
   ],
   "source": [
    "def init_weights(module):\n",
    "    if isinstance(module, nn.Linear):\n",
    "        print(f\"Initializing {module} with uniform\")\n",
    "        nn.init.uniform_(module.weight)\n",
    "    \n",
    "lin.apply(init_weights);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `Dataset` and `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.MNIST(\"data/raw/\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28 at 0x7FF9B45EDF98>, 0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/0lEQVR4nGNgGHhgPP/vfCMccgbv/vz58xa7nNnjv3/ev/xjyYYpxWXz4M/fP6dC/vytgggwIUnOPCDDwMBgxHOQQRdD0tibkfFQKeOL85OYGLG5ZTOPd6UoA8Pfz2gOVlv69+WFEAj775+lKHLsm/58cBeWgUkeRpG0/PPHHs5Blzz2dx+C8//vEWTX+hj834SQ/Pf/ArLG0D/PJOHWt//dxYMqeR8u1/znoTsDquREKMtg6Z+1DKgg7O9DCKPo3d9FaHIMoX9+TjKQDd308O/95RaYkn/+PL3+58+fI03oUgwMMsf//Pn758/LiZhSDAwMkg1//v7pVcUqR1cAAKxwbkTVIzd2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FF9A498C550>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Label: {dataset[1][1]}\")\n",
    "dataset[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=4,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## model + loss + optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  # from above\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(\n",
    "    [\n",
    "        {\"params\": model.conv1.parameters(), \"lr\": 0.001},\n",
    "        {\"params\": model.conv2.parameters()}\n",
    "    ],\n",
    "    lr=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, loss_fn, optimizer, train_dl, valid_dl, n_epochs: int):\n",
    "    for epoch in range(n_epochs):\n",
    "        # TRAIN\n",
    "        model.train()\n",
    "        for x, y in train_dl:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            y_ = model(x)\n",
    "            loss = loss_fn(y, y_)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # EVAL\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x, y in valid_dl:\n",
    "                x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "                y_ = model(x)\n",
    "                loss = loss_fn(y, y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Multiple GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Pre-Trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.models.resnet18(pretrained=True)\n",
    "torchvision.models.densenet121(pretrained=True)\n",
    "torchvision.models.inception_v3(pretrained=True)\n",
    "torchvision.models.squeezenet1_1(pretrained=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alexnet',\n",
      " 'bninception',\n",
      " 'cafferesnet101',\n",
      " 'densenet121',\n",
      " 'densenet161',\n",
      " 'densenet169',\n",
      " 'densenet201',\n",
      " 'dpn107',\n",
      " 'dpn131',\n",
      " 'dpn68',\n",
      " 'dpn68b',\n",
      " 'dpn92',\n",
      " 'dpn98',\n",
      " 'fbresnet152',\n",
      " 'inceptionresnetv2',\n",
      " 'inceptionv3',\n",
      " 'inceptionv4',\n",
      " 'nasnetalarge',\n",
      " 'nasnetamobile',\n",
      " 'pnasnet5large',\n",
      " 'polynet',\n",
      " 'resnet101',\n",
      " 'resnet152',\n",
      " 'resnet18',\n",
      " 'resnet34',\n",
      " 'resnet50',\n",
      " 'resnext101_32x4d',\n",
      " 'resnext101_64x4d',\n",
      " 'se_resnet101',\n",
      " 'se_resnet152',\n",
      " 'se_resnet50',\n",
      " 'se_resnext101_32x4d',\n",
      " 'se_resnext50_32x4d',\n",
      " 'senet154',\n",
      " 'squeezenet1_0',\n",
      " 'squeezenet1_1',\n",
      " 'vgg11',\n",
      " 'vgg11_bn',\n",
      " 'vgg13',\n",
      " 'vgg13_bn',\n",
      " 'vgg16',\n",
      " 'vgg16_bn',\n",
      " 'vgg19',\n",
      " 'vgg19_bn',\n",
      " 'xception']\n"
     ]
    }
   ],
   "source": [
    "import pretrainedmodels\n",
    "pprint(sorted(pretrainedmodels.model_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PyTorch 1.0\n",
    "- Focus: \"from research to production\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- API mostly unchanged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- distributed backend redesigned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `torch.jit` to compile models\n",
    "  - `torch.jit.trace`\n",
    "  - `torch.jit.script`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- LibTorch C++ frontend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- (ONNX - Open Neural Network eXchange format)\n",
    "  - (PyTorch -> ONNX -> whatever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ecosystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- high-level training libs (ignite, TNT, skorch, fast.ai, PyToune, MagNet, etc.)\n",
    "- AllenNLP, Flair, fairseq, Glow, Pyro, PySyft, GPyTorch\n",
    "- https://colab.research.google.com/ supports PyTorch\n",
    "- https://pytorch.org/ecosystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `tensorboardX`\n",
    "https://github.com/lanpa/tensorboardX\n",
    "\n",
    "![](notebooks/img/tensorboardx_demo.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Visdom\n",
    "\n",
    "![](notebooks/img/visdom.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recap\n",
    "\n",
    "- PyTorch is just stupid Python\n",
    "- PyTorch is like numpy (on the GPU and with autograd)\n",
    "- small and concise API surface\n",
    "- `Dataset` and `DataLoader`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `torch.jit` and ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- PyTorch and TensorFlow are converging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The End\n",
    "## Thanks! Q&A!\n",
    "\n",
    "(Material for the workshop https://github.com/sotte/pytorch_tutorial *WIP*)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
